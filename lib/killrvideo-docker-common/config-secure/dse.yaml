# Memory limit for DSE In-Memory tables as a fraction of system memory (the default is 0.2, or 20%)
max_memory_to_lock_fraction: 0.20

# # Can also be specified as a maximum in MB; the fraction value is ignored if this is set to a non-zero value.
# max_memory_to_lock_mb: 10240

##########################
# Authentication options
#
# These options are used if the authenticator option in cassandra.yaml is set to
# com.datastax.bdp.cassandra.auth.DseAuthenticator
#
# The enabled option controls whether the DseAuthenticator will authenticate users. If
# set to true users will be authenticated, if set to false they will not.
#
# DseAuthenticator allows multiple authentication schemes to be used at the same time.
# The schemes to be used are controlled by the default_scheme and allowed_schemes options.
# A driver can select the scheme to use during authentication.
#
# The default_scheme option selects which authentication scheme will be used if the driver
# does not request a specific scheme. This can be one of the following values:
#   internal - plain text authentication using the Cassandra password authenticator
#   ldap     - plain text authentication using the passthrough ldap authenticator
#   kerberos - gssapi authentication using the kerberos authenticator
# The other_schemes option is a list of schemes that can also be selected for use by a
# driver and can be a list of the above schemes.
#
# The scheme_permissions option controls whether roles need to have permission granted to
# them in order to use specific authentication schemes. These permissions can be granted
# only when the DseAuthorizer is used.
#
# The allow_digest_with_kerberos option controls whether digest-md5 authentication is also
# allowed when kerberos is one of the authentication schemes. If set to false, it will not
# be allowed. You must set allow_digest_with_kerberos to true in analytics clusters to use Hadoop
# inter-node authentication with Hadoop and Spark jobs.
#
# The plain_text_without_ssl controls how the DseAuthenticator reacts to plain text
# authentication requests over unencrypted client connections. It can be one of:
#   block  - block the request with an authentication error
#   warn   - log a warning about the request but allow it to continue
#   allow  - allow the request without any warning
#
# The transitional_mode option allows the DseAuthenticator to operate in a transitional
# mode during setup of authentication in a cluster. This can be one of the following values:
#   disabled   - transitional mode is disabled
#   permissive - Only super users are authenticated and logged in, all other
#                authentication attempts will be logged in as the anonymous user
#   normal     - If credentials are passed they are authenticated. If the
#                authentication is successful then the user is logged in, otherwise
#                the user is logged in as anonymous. If no credentials are passed,
#                then the user is logged in as anonymous
#   strict     - If credentials are passed they are authenticated. If the
#                authentication is successful, the user is logged in. If the
#                authentication fails, an authentication error is returned. If no
#                credentials are passed, the user is logged in as anonymous
authentication_options:
    enabled: true
#     default_scheme: internal
#     allow_digest_with_kerberos: true
#     plain_text_without_ssl: warn
#     transitional_mode: default
#     other_schemes:
#     scheme_permissions: false

##########################
# Role Management Options
#
# These options are used when the role_manager option in cassandra.yaml is set to
# com.datastax.bdp.cassandra.auth.DseRoleManager
#
# mode can be one of:
#   internal - the granting and revoking of roles is managed internally
#              using the GRANT ROLE and REVOKE ROLE statements
#   ldap - the granting and revoking of roles is managed by an external
#          LDAP server configured using the ldap_options.
role_management_options:
    mode: internal

##########################
# Authorization options
#
# The enabled option controls whether the DseAuthorizer will perform authorization. If
# set to true authorization is performed, if set to false it is not.
#
# The transitional_mode option allows the DseAuthorizer to operate in a transitional
# mode during setup of authorization in a cluster. This can be one of the following values:
#   disabled   - transitional mode is disabled
#   normal     - permissions can be granted to resources but are not enforced
#   strict     - permissions can be granted to resources and are enforced on
#                authenticated users. They are not enforced against anonymous
#                users
#   allow_row_level_security - In order for row level security to be used, this must be set to allow it
#                              for the entire system. true or false
authorization_options:
    enabled: true
#     transitional_mode: disabled
#     allow_row_level_security: false

##########################
# Kerberos options
#
# The qop is the Quality of Protection (QOP) values that clients and servers
# can use for each connection.  Below is a list of valid values and their meanings.
#   auth      - (default) authentication only
#   auth-int  - authentication plus integity protection of all transmitted data
#   auth-conf - authentication plus integrity protection and encryption of all
#               transmitted data
#
# Warning - Encryption using auth-conf is separate and completely independent
#           of whether encryption is done using SSL.  If auth-conf is selected here
#           and SSL is enabled, the transmitted data is encrypted twice.
kerberos_options:
    keytab: resources/dse/conf/dse.keytab
    service_principal: dse/_HOST@REALM
    http_principal: HTTP/_HOST@REALM
    qop: auth

##########################
# LDAP options
#
# These are options are used when the com.datastax.bdp.cassandra.auth.LdapAuthenticator
# is configured as the authenticator in cassandra.yaml

# ldap_options:
#     server_host:
#
#     # Port to use to connect to the LDAP server. This is normally 389 for unencrypted
#     # connections and 636 for ssl encrypted connections. If use_tls is set to true, use the
#     # unencrypted port
#     server_port: 389
#
#     # The distinguished name (DN) of the user that is used to search for other users on the
#     # LDAP server. This user should have only the necessary permissions to do the search
#     # If not present then an anonymous bind is used for the search
#     search_dn:
#
#     # Password of the search user
#     search_password:
#
#     # Set to true to use an SSL encrypted connection. In this case the server_port needs
#     # to be set to the LDAP port for the server
#     use_ssl: false
#
#     # Set to true to initiate a TLS encrypted connection on the default ldap port
#     use_tls: false
#
#     truststore_path:
#     truststore_password:
#     truststore_type: jks
#     user_search_base:
#     user_search_filter: (uid={0})
#
#     # Set to the attribute on the user entry containing group membership information.
#     user_memberof_attribute: memberof
#
#     # The group_search_type defines how group membership will be determined for a user. It
#     # can be one of:
#     #     directory_search - will do a subtree search of group_search_base using
#     #                        group_search_filter to filter the results
#     #     memberof_search  - will get groups from the memberof attribute of the user. This
#     #                        requires the directory server to have memberof support
#     group_search_type: directory_search
#     group_search_base:
#     group_search_filter: (uniquemember={0})
#
#     # The attribute in the group entry that holds the group name.
#     group_name_attribute: cn
#
#     # Validity period for the credentials cache in milli-seconds (remote bind is an expensive
#     # operation). Defaults to 0, set to 0 to disable.
#     credentials_validity_in_ms: 0
#
#     # Validity period for the search cache in seconds. Defaults to 0, set to 0 to disable.
#     search_validity_in_seconds: 0
#
#     connection_pool:
#         max_active: 8
#         max_idle: 8

# To ensure that records with TTLs are purged from DSE Search indexes when they expire, DSE
# periodically checks all indexes for expired documents and deletes them. These settings
# control the scheduling and execution of those checks.
ttl_index_rebuild_options:

    # By default, schedule a check every 300 seconds:
    fixed_rate_period: 300

    # The first check is delayed to speed up startup time:
    initial_delay: 20

    # All documents determined to be expired are deleted from the index during each check, but
    # to avoid memory pressure, their unique keys are retrieved and deletes issued in batches.
    # This determines the maximum number of documents per batch:
    max_docs_per_batch: 4096

    # Maximum number of search indexes that can execute TTL cleanup concurrently:
    thread_pool_size: 1

# DSE Search resource upload size limit in MB. A value of '0' disables resource uploading.
solr_resource_upload_limit_mb: 10

# Transport options for inter-node communication between DSE Search nodes.
shard_transport_options:
    # The cumulative shard request timeout, in milliseconds (default is 60000).
    netty_client_request_timeout: 60000

# ---- DSE Search index encryption options

solr_encryption_options:
#     # Whether to allocate shared index decryption cache off JVM heap.
#     # Default is off heap allocation (true).
#     decryption_cache_offheap_allocation: true

#     # The maximum size of shared DSE Search decryption cache, in MB.
#     # Default is 256 MB.
#     decryption_cache_size_in_mb: 256

# ---- DSE Search indexing settings

# # Max number of concurrent asynchronous indexing threads per Solr core. If set
# # to 1, the system reverts to the synchronous behavior, where data is
# # synchronously written into Cassandra and indexed by Solr.
# #
# # Default: On most Linux distributions, the number of physical CPU cores (even if those cores
# #          have multiple threads). On other platforms, this defaults to the number of logical
# #          CPU cores visible to the JVM. If the system property "cassandra.available_processors"
# #          is set, the default here will be that value divided by the number of threads per CPU core.
# max_solr_concurrency_per_core: 2
#
# # Allows back pressure system to adapt max auto soft commit time (defined per core in solrconfig.xml) to the actual load.
# # Setting is respected only for NRT (near real time) cores. When core has RT (real time) enabled, adaptive commits
# # are disabled regardless of this property value.
# #
# # Default: enabled (true)
# enable_back_pressure_adaptive_nrt_commit: true
#
# # The back pressure threshold is the target total number of queued asynchronous indexing requests per core;
# # the back pressure mechanism will throttle incoming requests to keep the queue size as close to the threshold as possible.
# #
# # Default: 1000 * max_solr_concurrency_per_core
# back_pressure_threshold_per_core: 2000
#
# # The max time to wait for flushing of async index updates, happening either
# # at Solr commit time or Cassandra flush time.
# # Flushing should always complete successfully, in order to fully sync Solr indexes
# # with Cassandra data, so should always be set at a reasonable high value.
# #
# # Default: 5 minutes
# flush_max_time_per_core: 5
#
# # The max time to wait for each Solr core to load upon startup or create/reload operations.
# # This is an advanced option, which should be changed only if any exceptions happen during core loading.
# #
# # Default: 5 minutes
# load_max_time_per_core: 5
#
# # Applies the configured Cassandra disk failure policy to index write failures.
# # Default is disabled (false).
# enable_index_disk_failure_policy: false

# # The directory to store index data; each DSE Search index will be stored under
# # a solrconfig_data_dir/keyspace.table directory.
# # Default is a solr.data directory inside Cassandra data directory, or as specified
# # by the dse.solr.data.dir system property
# solr_data_dir: /MyDir

# # The Lucene field cache has been deprecated, instead set docValues="true" on the field
# # in the schema.xml file.  After doing so RELOAD the core and reindex.
# # Default: false
# solr_field_cache_enabled: false

# ---- Solr CQL query options

# # Max number of threads to use for retrieving rows during CQL Solr queries.
# # This value is cross-request and cross-core.
# # Default is "number of available processors" * 10.
# cql_solr_query_executor_threads: 2
#
# # Max time in milliseconds to wait for either each row (pre-5.0) or all rows (5.0 onwards)
# # to be read from Cassandra during CQL Solr queries.
# # Default is 10000 (10 seconds).
# cql_solr_query_row_timeout: 10000

##########################
# Global performance service options

# # Maximum number of background threads used by the performance service.
# # Defaults to concurrent_writes specified in cassandra.yaml.
# performance_max_threads: 32
#
# # The number of queued tasks in the backlog when the number of performance_max_threads are busy (minimum 0).
# performance_queue_capacity: 32000
#
# # If the performance service requests more tasks than (performance_max_threads + performance_queue_capacity),
# # a dropped task warning will be issued. This indicates that collected statistics may not be up to date because the
# # server couldn't keep up under the current load.
#
# # You may either disable or reconfigure some services, or increase the queue size.

##########################
# Core performance service options

graph_events:
    ttl_seconds: 600

# cql_slow_log_options:
#     enabled: true
#
#     #  When t > 1, log queries taking longer than t milliseconds.
#     #      0 <= t <= 1,  log queries above t percentile
#     threshold: 200.0
#
#     # Initial number of queries before percentile filter becomes active
#     minimum_samples: 100
#
#     ttl_seconds: 259200
#
#     # keeps slow queries in-memory only and doesn't write data to C*
#     # WARNING - if this is set to 'false' then set threshold >= 2000, otherwise there will be a high load on C*
#     skip_writing_to_db: true
#
#     # the number of slow queries to keep in-memory
#     num_slowest_queries: 5

cql_system_info_options:
    enabled: false
    refresh_rate_ms: 10000

resource_level_latency_tracking_options:
    enabled: false
    refresh_rate_ms: 10000

db_summary_stats_options:
    enabled: false
    refresh_rate_ms: 10000

cluster_summary_stats_options:
    enabled: false
    refresh_rate_ms: 10000

spark_cluster_info_options:
    enabled: false
    refresh_rate_ms: 10000

# ---- Spark application stats options
spark_application_info_options:
    enabled: false
    refresh_rate_ms: 10000

    driver:
        # enables or disables writing of the metrics collected at Spark Driver to Cassandra
        sink: false

        # enables or disables Spark Cassandra Connector metrics at Spark Driver
        connectorSource: false

        # enables or disables JVM heap and GC metrics at Spark Driver
        jvmSource: false

        # enables or disables application state metrics
        stateSource: false

    executor:
        # enables or disables writing of the metrics collected at executors to Cassandra
        sink: false

        # enables or disables Spark Cassandra Connector metrics at executors
        connectorSource: false

        # enables or disables JVM heap and GC metrics at executors
        jvmSource: false

# Column Family Histogram data tables options
histogram_data_options:
    enabled: false
    refresh_rate_ms: 10000
    retention_count: 3

# User/Resource latency tracking settings
user_level_latency_tracking_options:
    enabled: false
    refresh_rate_ms: 10000
    top_stats_limit: 100
    quantiles: false

# ---- DSE Search Performance Objects

solr_indexing_error_log_options:
    enabled: false
    ttl_seconds: 604800
    async_writers: 1

solr_slow_sub_query_log_options:
    enabled: false
    ttl_seconds: 604800
    async_writers: 1
    threshold_ms: 3000

solr_update_handler_metrics_options:
    enabled: false
    ttl_seconds: 604800
    refresh_rate_ms: 60000

solr_request_handler_metrics_options:
    enabled: false
    ttl_seconds: 604800
    refresh_rate_ms: 60000

solr_index_stats_options:
    enabled: false
    ttl_seconds: 604800
    refresh_rate_ms: 60000

solr_cache_stats_options:
    enabled: false
    ttl_seconds: 604800
    refresh_rate_ms: 60000

solr_latency_snapshot_options:
    enabled: false
    ttl_seconds: 604800
    refresh_rate_ms: 60000

# Node health is a score-based representation of how fit a node is to handle queries. The score is a
# function of how long a node has been up and the rate of dropped mutations in the recent past.
node_health_options:
    refresh_rate_ms: 60000
    # The amount of continuous uptime required for the node to reach the maximum uptime score. If you
    # are concerned with consistency during repair after a period of downtime, you may want to
    # temporarily increase this to the expected time it will take to complete repair.
    #
    # (Default: 86400 seconds, or 1 day)
    uptime_ramp_up_period_seconds: 86400
    # The window in the past over which the rate of dropped mutations affects the node health score.
    # (Default: 30 minutes)
    dropped_mutation_window_minutes: 30

# If enabled (true), replica selection for distributed DSE Search queries takes node health into account
# when multiple candidates exist for a particular token range. Set this to false to ignore
# node health when choosing replicas.
#
# Health-based routing allows us to make a trade-off between index consistency and query throughput. If
# the primary concern is query performance, it may make sense to set this to "false".
#
# Default is enabled (true).
enable_health_based_routing: true

# If enabled (true), DSE Search reindexing of bootstrapped data will happen asynchronously, and the node will join the ring straight
# after bootstrap.
#
# Default is disabled (false): the node will wait for reindexing of bootstrapped data to finish before joining the ring.
async_bootstrap_reindex: false

# Lease metrics. Enable these to help monitor the performance of the lease subsystem.
# ttl_seconds controls how long the log of lease holder changes persists.
lease_metrics_options:
    enabled: false
    ttl_seconds: 604800

# The directory where system keys are kept
#
# Keys used for sstable encryption must be distributed to all nodes
# DSE must be able to read and write to the directory.
#
# This directory should have 700 permissions and belong to the dse user
system_key_directory: /etc/dse/conf

# If this is set to true, DSE will expect the following config values to be encrypted:
#     resources/cassandra/conf/cassandra.yaml:
#         server_encryption_options.keystore_password
#         server_encryption_options.truststore_password
#         client_encryption_options.keystore_password
#         client_encryption_options.truststore_password
#    resources/dse/conf/dse.yaml:
#         ldap_options.search_password
#         ldap_options.truststore_password
#
# It's an error if the passwords aren't encrypted.
# Config values can be encrypted with "dsetool encryptconfigvalue"
config_encryption_active: false

# The name of the system key used to encrypt / decrypt passwords stored
# in configuration files.
#
# If config_encryption_active is true, it's an error if a valid key with
# this name isn't in the system key directory keyfiles, and KMIP managed
# keys can be created with "dsetool createsystemkey"
config_encryption_key_name: system_key

##########################
# Spark-related settings

# The fraction of available system resources to be used by Spark Worker.
# This the only initial value, once it is reconfigured, the new value is stored
# and retrieved on next run.
initial_spark_worker_resources: 0.7

# The length of a shared secret used to authenticate Spark components and encrypt the connections between them.
# Note that this is not the strength of the cipher used for encrypting connections.
spark_shared_secret_bit_length: 256

# Enables Spark security based on shared secret infrastructure. This means enabling mutual authentication of
# the Spark components as well as optionally encryption of communication channels except Web UI.
spark_security_enabled: false

# Enables encryption on Spark connections except Web UI. It uses Digest-MD5 SASL based encryption mechanism.
# This options does make sense only if spark_security_enabled is true.
spark_security_encryption_enabled: false

# # How often Spark plugin should check for Spark Master / Worker readiness to start. The value is
# # a time (in ms) between subsequent retries.
# spark_daemon_readiness_assertion_interval: 1000

# Beginning in DSE 5.1: Communication between Spark applications and the resource manager are now routed through
# the CQL native protocol. Enabling client encryption in the cassandra.yaml will also enable encryption for
# the communication with the DSE Spark Master. The communication between Spark Driver and Spark Executors can be
# secured by enabling Spark authentication and encryption for that application.
# On the other hand, mutual authentication and encryption of communication between DSE Spark Master and Workers are
# managed by spark_security_enabled and spark_security_encryption_enabled defined above.

# Spark UI options apply to Spark Master and Spark Worker UIs - thus Spark daemon UIs in general. They do NOT apply to
# user applications even if they run in cluster mode.
spark_ui_options:
    # Allowed values are:
    # inherit - SSL settings are inherited from Cassandra client encryption options
    # custom - SSL settings from encryption_options below
    encryption: inherit

    encryption_options:
        enabled: false
        keystore: resources/dse/conf/.ui-keystore
        keystore_password: cassandra
        # require_client_auth: false
        # Set trustore and truststore_password if require_client_auth is true
        # truststore: resources/dse/conf/.ui-truststore
        # truststore_password: cassandra
        # More advanced defaults below:
        # protocol: TLS
        # algorithm: SunX509
        # store_type: JKS
        # cipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_AES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA]

# Configure the way how the driver and executor processes are created and managed.
spark_process_runner:
    # Allowed options are: default, run_as
    runner_type: default

    # RunAs runner uses sudo to start Spark drivers and executors. A set of predefined fake users, called slots, is used
    # for this purpose. All drivers and executors owned by some DSE user are run as some slot user x. At the same time
    # drivers and executors of any other DSE user use different slots.
    # Setting up slots:
    # 1. create n users (n - number of slots), call them, say slot1, slot2, ..., slotn, with no login; each such user
    #    should have primary group the same as its name, so for example slot1:slot1, slot2:slot2, ...
    # 2. add DSE service user (the one as who DSE server is run) to the slot user groups - DSE service user has to be
    #    in all slot user groups
    # 3. modify sudoers files so that:
    #    a) DSE service user can execute any command as any slot user without providing a password
    #    b) umask is overridden to 007 for those commands so that files created by sub-processes will not be accessible
    #       by anyone by default,
    #    For example, if we have two slot users slot1, slot2, and DSE service user dse, this should be added to sudoers:
    #    Runas_Alias     SLOTS = slot1, slot2
    #    Defaults>SLOTS  umask=007
    #    Defaults>SLOTS  umask_override
    #    dse             ALL=(SLOTS) NOPASSWD: ALL
    run_as_runner_options:
        user_slots:
            - slot1
            - slot2

##########################
# DSE File System options
# dsefs_options:
#
#     # Determines whether DSEFS should be enabled on this node.
#     # If not present, DSEFS is enabled only on the nodes that run Spark workload.
#     enabled:
#
#     # Keyspace for storing the DSE FS metadata
#     keyspace_name: dsefs
#
#     # The local directory for storing node-local metadata e.g. the node identifier
#     # The amount of data stored there is tiny, so no special throughput, latency nor capacity are required.
#     # The work directory must not be shared by DSE FS nodes.
#     work_dir: /var/lib/dsefs
#
#     # Port for DSE FS clients, the service on this port will be bound to RPC address.
#     public_port: 5598
#
#     # Port for internode communication, must be not visible from outside of the cluster.
#     # It will be bound to listen address.
#     private_port: 5599
#
#     # Set of directories for storing the file data. 'dir' attribute is mandatory.
#     # It is recommended to put them on different physical devices than devices used for Cassandra.
#     # Using multiple directories on JBOD improves performance and capacity.
#     data_directories:
#         - dir: /var/lib/dsefs/data
#
#           # How much data should be placed in this directory relative to other directories in the cluster
#           storage_weight: 1.0
#
#           # Reserved space (in bytes) that is not going to be used for storing blocks
#           min_free_space: 5368709120
#
#     # More advanced settings below:
#
#     # How long DseFs Server is going to wait for services to bootstrap
#     service_startup_timeout_ms: 30000
#
#     # How long DseFs Server is going to wait for services to close
#     service_close_timeout_ms: 600000
#
#     # How long DseFs Server is going to wait close all pending connections during shutdown
#     server_close_timeout_ms: 2147483647 # Integer.MAX_VALUE
#
#     # The maximum accepted size of a compression frame (compression frame size is specified by a user during file
#     # upload)
#     compression_frame_max_size: 1048576
#
#     # Maximum number of elements in single DseFs Server query cache. DseFs reuses this value for every cache that
#     # stores database query results.
#     query_cache_size: 2048
#
#     # How long DseFs Server query cache element exists in cache. DseFs reuses this value for every cache that
#     # stores database query results.
#     query_cache_expire_after_ms: 2000
#
#     gossip_options:
#         # The delay between gossip rounds
#         round_delay_ms: 2000
#
#         # How long to wait after registering the Location and reading back all other Locations from Cassandra
#         startup_delay_ms: 5000
#
#         # How long to wait after announcing shutdown before shutting down the node
#         shutdown_delay_ms: 10000
#
#     rest_options:
#         # How long RestClient is going to wait for a response corresponding to a given request
#         request_timeout_ms: 330000
#
#         # How long RestClient is going to wait for establishing a new connection
#         connection_open_timeout_ms: 55000
#
#         # How long RestClient is going to wait until all pending transfers are complete before closing
#         client_close_timeout_ms: 60000
#
#         # How long to wait for the server rest call to complete
#         server_request_timeout_ms: 300000
#
#         # How long to wait until idle connection is closed, 0 if disabled
#         idle_connection_timeout_ms: 0

#     transaction_options:
#         # How long to allow a transaction to run before considering it for timing out and rollback
#         transaction_timeout_ms: 60000
#
#         # How long to wait before retrying a transaction aborted due to a conflict
#         conflict_retry_delay_ms: 10
#
#         # How many times the transaction is retried in case of a conflict before giving up
#         conflict_retry_count: 40
#
#         # How long to wait before retrying a failed transaction payload execution
#         execution_retry_delay_ms: 1000
#
#         # How many times to retry executing the payload before signaling the error to the application
#         execution_retry_count: 3
#
#     block_allocator_options:
#         # The overflow_margin_mb and overflow_factor options control how much additional data can be placed
#         # on the local (coordinator) before the local node overflows to the other nodes.
#         # A local node is preferred for a new block allocation, if
#         # used_size_on_the_local_node < average_used_size_per_node * overflow_factor + overflow_margin.
#         # The trade-off is between data locality of writes and balancing the cluster.
#         # To disable the preference for allocating blocks on the coordinator node, set these values to 0 MB and 1.0.
#         overflow_margin_mb: 1024
#         overflow_factor: 1.05

##########################
# Audit logging options
audit_logging_options:
    enabled: false

    # The logger used for logging audit information
    # Available loggers are:
    #   CassandraAuditWriter - logs audit info to a cassandra table. This logger can be run either synchronously, or
    #                          asynchronously. Audit logs are stored in the dse_audit.audit_log table.
    #                          When run synchronously, a query will not execute until it has been written
    #                          to the audit log table successfully. If there is a failure between when an audit event is
    #                          written, and it's query is executed, the audit logs may contain queries that were never
    #                          executed.
    #   SLF4JAuditWriter -     logs audit info to an slf4j logger. The logger name is `SLF4JAuditWriter`,
    #                          and can be configured in the logback.xml file.
    logger: SLF4JAuditWriter

#     # Comma separated list of audit event categories to be included or excluded from the audit log.
#     # Defaults to including all categories and keyspaces.
#     # Categories are: QUERY, DML, DDL, DCL, AUTH, ADMIN, ERROR
#     # Specify either included or excluded categories. Specifying both is an error
#     included_categories:
#     excluded_categories:

#     # Comma separated list of keyspaces to be included or excluded from the audit log.
#     # Specify either included or excluded keyspaces. Specifying both is an error
#     included_keyspaces:
#     excluded_keyspaces:

    # The amount of time, in hours, audit events are retained by supporting loggers
    # Currently, only the CassandraAuditWriter supports retention time
    # values of 0 or less retain events forever
    retention_time: 0

    cassandra_audit_writer_options:
        # Sets the mode the writer runs in.
        #
        # When run synchronously, a query is not executed until the audit event is successfully written.
        #
        # When run asynchronously, audit events are queued for writing to the audit table, but are
        # not necessarily logged before the query executes. A pool of writer threads consumes the
        # audit events from the queue, and writes them to the audit table in batch queries. While
        # this substantially improves performance under load, if there is a failure between when
        # a query is executed, and it's audit event is written to the table, the audit table may
        # be missing entries for queries that were executed.
        # valid options are 'sync' and 'async'
        mode: sync

        # The maximum number of events the writer will dequeue before writing them out to the table.
        # If you're seeing warnings in your logs about batches being too large, decrease this value.
        # Increasing batch_size_warn_threshold_in_kb in cassandra.yaml is also an option, but make sure you understand
        # the implications before doing so.
        #
        # Only used in async mode. Must be >0
        batch_size: 50

        # The maximum amount of time in milliseconds an event will be dequeued by a writer before being written out. This
        # prevents events from waiting too long before being written to the table when there's not a lot of queries happening.
        #
        # Only used in async mode. Must be >0
        flush_time: 500

        # The number of worker threads asynchronously logging events to the CassandraAuditWriter.
        #
        # Only used in async mode. Must be >0
        num_writers: 10

        # The size of the queue feeding the asynchronous audit log writer threads. When there are more events being
        # produced than the writers can write out, the queue will fill up, and newer queries will block until there
        # is space on the queue.
        # If a value of 0 is used, the queue size will be unbounded, which can lead to resource exhaustion under
        # heavy query load.
        queue_size: 10000

        # the consistency level used to write audit events
        write_consistency: QUORUM

#         # Where dropped events are logged
#         dropped_event_log: /var/log/cassandra/dropped_audit_events.log

#         # Partition days into hours by default
#         day_partition_millis: 3600000

##########################
# System information encryption settings
#
# If enabled, system tables that may contain sensitive information (system.batchlog,
# system.paxos), hints files and Cassandra commit logs are encrypted with the
# encryption settings below.
#
# If DSE Search index encryption is enabled, DSE Search index files are also encrypted with the settings below.
# If backing C* table encryption is enabled, DSE Search commit log is encrypted with settings below.
#
# When enabling system table encryption on a node with existing data, run
# `nodetool upgradesstables -a` on the listed tables to encrypt existing data
#
# When tracing is enabled, sensitive info will be written into the tables in the
# system_traces keyspace. Those tables should be configured to encrypt their data
# on disk by using an encrypting compressor.
#
# DataStax recommends using remote encryption keys from a KMIP server when using Transparent Data Encryption (TDE) features.
# Local key support is provided when a KMIP server is not available.
system_info_encryption:
    enabled: false
    cipher_algorithm: AES
    secret_key_strength: 128
    chunk_length_kb: 64

#     # Selects an alternate key provider for local encryption. Useful for using a kmip host as a key provider.
#     key_provider: KmipKeyProviderFactory

#     # If KmipKeyProviderFactory is used for system_info_encryption, this specifies the kmip host to be used.
#     kmip_host: kmip_host_name

##########################
# Kmip hosts options
#
# Connection settings for key servers supporting the kmip protocol
# this allows DSE's encryption features to use keys that are not stored
# on the same machine running DSE.
#
# Hosts are configured as <kmip_host_name>: {connection_settings}, which maps a user definable
# name to a set of hosts, truststores, etc used with a particular key server. This name is then
# used when referring to kmip hosts. DSE supports multiple kmip hosts.

# kmip_hosts:
#     # The unique name of this kmip host/cluster which is specified in the table schema.
#     host.yourdomain.com:
#
#         # Comma-separated list of kmip hosts host[:port]
#         # The current implementation of KMIP connection management only supports failover, so all requests will
#         # go through a single KMIP server. There is no load balancing. This is because there aren't any KMIP servers
#         # available (that we've found) that support read replication, or other strategies for availability.
#         #
#         # Hosts are tried in the order they appear here. So add them in the same sequence they'll fail over in
#         hosts: kmip1.yourdomain.com, kmip2.yourdomain.com
#
#         # keystore/truststore info
#         keystore_path: /path/to/keystore.jks
#         keystore_type: jks
#         keystore_password: password
#
#         truststore_path: /path/to/truststore.jks,
#         truststore_type: jks
#         truststore_password: password
#
#         # Keys read from the KMIP hosts are cached locally for the period of time specified below.
#         # The longer keys are cached, the fewer requests are made to the key server, but the longer
#         # it takes for changes (ie: revocation) to propagate to the DSE node
#         key_cache_millis: 300000
#
#         # Socket timeout in milliseconds.
#         timeout: 1000

# # When 'driver' DSE Search will use Solr cursor paging when pagination is enabled by the CQL driver.
# #
# # When 'off' DSE Search will ignore the driver's pagination settings and use normal Solr paging unless:
# #   - The current workload is an analytics workload (ex. SearchAnalytics).
# #   - The query parameter 'paging' is set to 'driver'.
# #
# # Default is 'off'
# #
# cql_solr_query_paging: off

# Local settings for tiered storage
#
# Tiered supports multiple disk configurations, which are configured as <config_name> : <config_settings>, and specified in DDL
# The tiers themselves are unnamed, and are just collections of paths, which need to be defined in the order they're to be used.
# Typically, you'd put your fastest storage in the top tier, and go down from there.
#
# Storage configurations don't need to be homogenous across the cluster, and internally, each node will only make use of the
# the number of tiers it actually has configured, or the number of tiers configured to be used in the DDL, whichever is less.
#
# Although the behavior of the tiered strategy for a given table is configured in the DDL, these settings can
# be overridden locally, per node, by specifying 'local_options' : {<k>:<v>, ...} in a config. This can be useful for testing
# options before deploying cluster wide, or for storage configurations which don't map cleanly to the DDL configuration.
#
# tiered_storage_options:
#     strategy1:
#         tiers:
#             - paths:
#                 - /mnt1
#                 - /mnt2
#             - paths: [ /mnt3, /mnt4 ]
#             - paths: [ /mnt5, /mnt6 ]
#
#         local_options:
#             k1: v1
#             k2: v2
#
#     'another strategy':
#         tiers: [ paths: [ /mnt1 ] ]

##########################
# DSE Advanced Replication configuration settings
#
# DSE Advanced replication supports one-way distributed data replication from remote
# clusters to central data hubs.
# When conf_driver_password_encryption_enabled: true, the configured passwords (including C* password, SSL keystore/truststore
#                                                     password, etc.) stored in the advrep config are expected to be encrypted
#                                                     with the dse configuration encryption using the systemkey. The same systemkey
#                                                     that was used to create the passwords, must be copied to every node in
#                                                     the cluster.
# advanced_replication_options:
#     enabled: false
#     conf_driver_password_encryption_enabled: false

#     # The directory under which Advanced Replication files (e.g. replication log files) will be stored.
#     advanced_replication_directory: /var/lib/cassandra/advrep

#     # The base path that will be prepended to paths in the Advanced Replication
#     # configuration locations, including locations to SSL keystore, SSL truststore etc.
#     security_base_path: /base/path/to/advrep/security/files/

##########################
# These internode_messaging_options configure network services for internal communication
# for all nodes. These settings must be identical on all nodes in the cluster.
internode_messaging_options:
    # TCP listen port (mandatory)
    port: 8609

#     # Max message frame length (default 256MB)
#     frame_length_in_mb: 256

#     # Number of server acceptor threads (default is number of available processors)
#     server_acceptor_threads: 8

#     # Number of server worker threads (default is number of available processors * 8)
#     server_worker_threads: 16

#     # Max number of client connections
#     client_max_connections: 100

#     # Number of client worker threads (default is number of available processors * 8)
#     client_worker_threads: 16

#     # Timeout for comm handshake process (default is 10 seconds)
#     handshake_timeout_seconds: 10

#     # Client request timeout, in seconds (default is 60).
#     client_request_timeout_seconds: 60

##########################
# Graph configuration
# Contains all system-level configuration options and those shared between graph
# instances.
graph:
    # The number of stale rows per second to clean from each graph's adjacency cache.
    # Value: integer.
    adjacency_cache_clean_rate: 1024

    # The maximum entry size in each graph's adjacency cache.  When set to zero, the
    # default is calculated based on the cache size and the number of CPUs.  Entries
    # that would exceed this size are quietly dropped by the cache without producing
    # an explicit error or log message. Value: integer.
    adjacency_cache_max_entry_size_in_mb: 0

    # The amount of ram to allocate to each graph's adjacency (edge and property)
    # cache. Value: integer.
    adjacency_cache_size_in_mb: 128

    # Maximum time to wait for an analytic (Spark) traversal to evaluate. Value: a
    # duration in minutes.
    analytic_evaluation_timeout_in_minutes: 10080

    # Enables or disables Gremlin Server. Value: boolean.
    gremlin_server_enabled: true

    # The number of stale entries per second to clean from the adjacency cache. Value:
    # integer.
    index_cache_clean_rate: 1024

    # The maximum entry size in the index adjacency cache.  When set to zero, the
    # default is calculated based on the cache size and the number of CPUs.  Entries
    # that would exceed this size are quietly dropped by the cache without producing
    # an explicit error or log message. Value: integer.
    index_cache_max_entry_size_in_mb: 0

    # The amount of ram to allocate to the index cache. Value: integer.
    index_cache_size_in_mb: 128

    # The maximum number of CQL queries that can be queued as a result of Gremlin
    # requests.  Incoming queries are rejected if the queue size exceeds this setting.
    # Value: integer.
    max_query_queue: 10000

    # The maximum number of threads to use for graph queries on Cassandra.  When this
    # option is not set, its effective default is 10 times either the gremlinPool
    # setting (if gremlinPool is present in this file and nonzero), or the number of
    # available CPU cores (if gremlinPool is not present in this file or set to zero).
    # The gremlinPool setting lives under the gremlin_server subsection of the graph
    # section in dse.yaml. Value: integer.
    # max_query_threads (no explicit default)

    # Maximum time to wait for a real-time traversal to evaluate. Value: a duration in
    # seconds.
    realtime_evaluation_timeout_in_seconds: 30

    # Maximum time to wait for cassandra to agree on schema versions before timing
    # out. Value: a duration in milliseconds.
    schema_agreement_timeout_in_ms: 10000

    # Controls automatic schema creation.  Setting this to "Development" permits
    # loading graph data without explicitly specifying a graph schema through the
    # graph schema API beforehand.  Setting this to "Production" requires explicitly
    # specifying a graph schema through the graph schema API before loading any
    # dependent graph data (vertices, edges, properties). Value: one of Development,
    # Production, Default.
    schema_mode: Production

    # Maximum time to wait for a graph-system request to evaluate.  Creating a new
    # graph is an example of a graph-system request. Value: a duration in seconds.
    system_evaluation_timeout_in_seconds: 180

    # The number of samples to keep when aggregating log events.   Only a small subset
    # of graph'slog statements use this system.  Modifying this setting is rarely
    # necessary or helpful. Value: integer.
    window_size: 100000

    # The maximum number of parameters that can be passed on a graph query request for both TinkerPop drivers
    # and those using the Cassandra native protocol. Generally speaking, it is considered an anti-pattern to
    # pass "massive" numbers of parameters on requests, as it increases the script evaluation time. Consider
    # other methods for parameterizing scripts (like passing a single Map or List if many arguments are needed)
    # prior to increasing this value. Future releases will have this value set at 16.
    max_query_params: 256

    # Configuration options for standard vertex ID assignment and partitioning
    # strategies.
    ids:
        # Graph's standard vertex ID allocator operates on blocks of contiguous IDs.  Each
        # block is allocated using a Cassandra lightweight transaction, which requires
        # coordination latency.  To hide the cost of allocating a standard ID block, the
        # allocator begins asynchronously buffering a replacement block whenever a current
        # block is nearly empty.  This parameter defines "nearly empty".  It expresses, as
        # a floating point number between 0 and 1, how much of a standard ID block can be
        # used before graph starts asynchronously allocating its replacement.  This
        # setting has no effect on custom IDs. Value: double.
        block_renew: 0.8

        # For graphs using standard vertex IDs, if a transaction creates multiple
        # vertices, the allocator attempts to assign vertex IDs that colocate vertices on
        # the same Cassandra replicas.  If an especially large vertex cohort is created,
        # the allocator chunks the vertex creation and assigns a random target location to
        # avoid load hotspotting.  This setting controls the vertex chunk size.  The
        # setting has no effect on custom IDs. Value: long.
        community_reuse: 28

        # Must be set to either DC_LOCAL or GLOBAL.  If set to DC_LOCAL, then
        # datacenter_id must be correctly configured on every node in the cluster.  If set
        # to GLOBAL, then datacenter_id is irrelevant and its value is ignored.  This
        # option must have the same value on every node in any given cluster.  Its value
        # can only be changed when the entire cluster is stopped.  This setting has no
        # effect on custom IDs. Value: one of GLOBAL, DC_LOCAL.
        consistency_mode: GLOBAL

        # This option is ignored when consistency_mode is not set to DC_LOCAL.  When
        # consistency_mode is set to DC_LOCAL, this must be set to an arbitrary value
        # between 1 and 127, inclusive.  Any given value for this option must appear in at
        # most one datacenter whenever consistency_mode is DC_LOCAL.  Violating this
        # constraint will corrupt the database.  This setting has no effect on custom IDs.
        # Value: integer.
        # datacenter_id (no explicit default)

        # An integer between 1 and 2^24 (both inclusive) that affects maximum ID capacity
        # and the maximum storage space used by ID allocations.  Lower values reduce both
        # storage space consumed and lightweight transaction overhead imposed at startup.
        # Lower values also reduce the total number of IDs that can be allocated over the
        # life of a graph, because this parameter is proportional to the allocatable ID
        # space.  However, the proportion coefficient is Long.MAX_VALUE (2^63-1), so ID
        # headroom should be sufficient, practically speaking, even if this is set to 1.
        # This setting has no effect on custom IDs. Value: integer.
        id_hash_modulus: 20

        # Graph's standard vertex ID allocator claims uniformly-sized blocks of contiguous
        # IDs using lightweight transactionson Cassandra.  This setting controls the size
        # of each block.  This setting has no effect on custom IDs. Value: integer.
        member_block_size: 512

    # Contains all registered state listeners identified by their name.
    listener:
#         # On the following line, "listener_name" is a placeholder string.  This can be
#         # changed to an arbitrary string composed of lowercase letters, numbers, and
#         # underscores, where the string begins with a lowercase letter.
#         listener_name:
#             # The names of state types that are ignored. All state types but those given are
#             # listened to. Value: YAML-formatted list of strings.
#             black_types:  # This list is empty by default
#
#             # The interval in which the state values are logged. Value: a duration in seconds.
#             interval_in_seconds: 3600
#
#             # The type of the state listener. Must be one of the following values: slf4j.
#             # Value: string.
#             type: slf4j
#
#             # The names of state types that should be listened. Only those state types are
#             # listened to and all others ignored. Value: YAML-formatted list of strings.
#             white_types:  # This list is empty by default
#
    # Configuration options graph's internal query forwarding and lightweight
    # messaging system.
    msg:
        # Graph messages must be acknowledged within this interval, or else the message
        # will be assumed dropped/failed.  Graph will retry the message or fail the
        # responsible request if the retry limit has been exceeded. Value: a duration in
        # milliseconds.
        graph_msg_timeout_in_ms: 5000

    # Contains all registered event observers identified by their name.
    observer:
#         # On the following line, "observer_name" is a placeholder string.  This can be
#         # changed to an arbitrary string composed of lowercase letters, numbers, and
#         # underscores, where the string begins with a lowercase letter.
#         observer_name:
#             # The names of event types that are ignored. All event types but those given are
#             # observed. Value: YAML-formatted list of strings.
#             black_types:  # This list is empty by default
#
#             # The names of the graphs for which events are observed. Value: YAML-formatted
#             # list of strings.
#             observed_graphs:  # This list is empty by default
#
#             # Threshold at which slow events get reported. Value: a duration in milliseconds.
#             slow_threshold_in_ms: 300000
#
#             # The type of the event observer. Must be one of the following values: slf4j,
#             # slow_request. Value: string.
#             type: slf4j
#
#             # The names of event types that should be observed. Only those event types are
#             # observed and all others ignored. Value: YAML-formatted list of strings.
#             white_types:  # This list is empty by default
#
    # Shared data.
    shared_data:
        # The interval between refreshes. Value: a duration in milliseconds.
        refresh_interval_in_ms: 60000

    gremlin_server:
        port: 8182

        threadPoolWorker: 2

        # The number of "Gremlin" threads available to execute actual scripts in a ScriptEngine. This pool represents
        # the workers available to handle blocking operations in Gremlin Server. When set to zero, this value will
        # be defaulted to the value of the JVM property "cassandra.available_processors" (if set)
        # or to Runtime.getRuntime().availableProcessors().
        gremlinPool: 0
        maxContentLength: 65536000

        # The maximum length of the content or each chunk. If the content length exceeds this value, the transfer
        # encoding of the decoded request will be converted to chunked and the content will be split into multiple
        # HttpContent objects. If the transfer encoding of the HTTP request is chunked already, each chunk will be split
        # into smaller chunks if the length of the chunk exceeds this value.
        maxChunkSize: 4096000

        # The maximum length of the initial line (e.g. "GET / HTTP/1.0") processed in a request, which essentially
        # controls the maximum length of the submitted URI.
        maxInitialLineLength: 4096

        # The maximum length of all headers.
        maxHeaderSize: 8192

        # Maximum number of request components that can be aggregated for a message.
        maxAccumulationBufferComponents: 1024

        # Defines the size in which the result of a request is "batched" back to the client. In other words, if set to 1,
        # then a result that had ten items in it would get each result sent back individually. If set to 2 the same ten
        # results would come back in five batches of two each. Note that this value can be overridden per request.
        resultIterationBatchSize: 64

        # Try to use epoll event loops (works only on Linux os) instead of netty NIO.
        useEpollEventLoop: false

        # A List of Map settings, where each Map represents a MessageSerializer implementation to use along with its
        # configuration.
        serializers:
            - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistry], classResolverSupplier: com.datastax.bdp.graph.impl.tinkerpop.io.DseClassResolverProvider }}
            - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoLiteMessageSerializerV1d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistry], classResolverSupplier: com.datastax.bdp.graph.impl.tinkerpop.io.DseClassResolverProvider }}
            - { className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0, config: { serializeResultToString: true }}
            - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV1d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistry] }}
            - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerGremlinV2d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistryV2d0, com.datastax.bdp.graph.impl.tinkerpop.io.DseGraphIoRegistryV2d0] }}
            - { className: org.apache.tinkerpop.gremlin.driver.ser.GraphSONMessageSerializerV1d0, config: { ioRegistries: [org.apache.tinkerpop.gremlin.tinkergraph.structure.TinkerIoRegistry] }}

#        # The gremlin-groovy script engine will always be added even if the configuration option is not present.
#        # Additional imports may be added in the configuration for that script engine.
#         scriptEngines:
#            gremlin-groovy:
#                 config:
#                     # To disable the gremlin groovy sandbox entirely
#                     sandbox_enabled: false
#                     sandbox_rules:
#
#                         # To completely whitelist a package add the package name here
#                         whitelist_packages:
#                         - package.name
#
#                         # To whitelist an individual type add the name of the type here
#                         whitelist_types:
#                         - fully.qualified.class.name
#
#                         # To whitelist a super class add the name of the type here
#                         whitelist_supers:
#                         - fully.qualified.class.name
